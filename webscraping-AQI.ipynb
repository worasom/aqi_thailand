{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Pollution Data from Thailand EPA\n",
    "\n",
    "Thailand's environment protection agency(EPA) makes pollution data accessible through their [website](http://www.aqmthai.com/). However, obtaining bulk record by hand can be tedious. This notebook explains how to automatically scrape data with from this website using selenium and beautiful soup library, which can be applied to any website with similar structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap data from a single station.\n",
    "\n",
    "The website provide three ways of obtaining pollution data: the first tab provides an hourly pollution report for all measurement stations, the second tab is for a historical data for a specific day and hours for all measurement stations, the third tab allow a batch request historical data from specified station. Data a month back from today is available.\n",
    "\n",
    "<img src=\"data/aqi_front4.png\" width=\"500\">\n",
    "\n",
    "I am going to show how scrap data using the third tab, which involves the follow steps: (1) select the station number from the area and province you are interested in, (2) pick the time, (3) pick the parameters, (4) ask to display the table, save the data from the display table as html, and (5) click \"Next\" to show the rest of the table until all the data is scrapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Firefox to open the website\n",
    "browser = webdriver.Firefox()\n",
    "url='http://www.aqmthai.com/public_report.php'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, select a station ID. After inspecting the HTML element, I learned that it is listed under a select tag with id=\"stationId.\"\n",
    "\n",
    "<img src=\"data/aqi_station.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select stationId\n",
    "sta_name = \"11t\"\n",
    "station = Select(browser.find_element_by_css_selector('select[id=\"stationId\"]'))\n",
    "station.select_by_value(sta_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we select the time range we are interested in. I am interested in all data, which go backward a month, so I am going to use the default date, and pick the time from midnight to 23:00 on that day. Then I pick the parameter I am interested in. The tricky part is each station have different parameters, so  it is important to read the parameters displayed before selecting the parameters. Then ask selenium to hick the display table button, under the name \"bt_show_table\". Sometimes the website has a slow response, so I asked Python to wait 10 second each step before continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select time\n",
    "start_hr = Select(browser.find_element_by_id('startHour'))\n",
    "start_hr.select_by_index(0)\n",
    "start_min = Select(browser.find_element_by_id('startMin'))\n",
    "start_min.select_by_index(0)\n",
    "stop_hr = Select(browser.find_element_by_id('endHour'))\n",
    "stop_hr.select_by_index(23)\n",
    "stop_min = Select(browser.find_element_by_id('endMin'))\n",
    "stop_min.select_by_index(59)\n",
    "\n",
    "#select parameters to display\n",
    "param = Select(browser.find_element_by_id('parameterSelected'))\n",
    "for i in range(16):\n",
    "    param.select_by_index(i)\n",
    "    \n",
    "#Retrive data \n",
    "button = browser.find_element_by_name('bt_show_table')\n",
    "button.click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data as HTML and click the \"Next\" button to display more data and save these data. In the next section, I am going to show how to extract the data from the saved HTML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download webpage as html file for scraping \n",
    "page = browser.page_source\n",
    "with open('web/page1.html','w', encoding='utf-8') as f:\n",
    "    f.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums =[str(i) for i in range(2,9)]\n",
    "print(nums)\n",
    "\n",
    "# click the next button to display the next page. There are 7 more pages to click \n",
    "for num in nums:\n",
    "    next_button = browser.find_element_by_name('bt_next_page')\n",
    "    next_button.click()\n",
    "    time.sleep(10)\n",
    "    page = browser.page_source\n",
    "    \n",
    "    with open('web/page'+num+'.html','w', encoding='utf-8') as f:\n",
    "        f.write(page)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data from HTML files\n",
    "\n",
    "After obtaining the HTML files are saved in my local drive, I use beautifulsoup to and pandas to append the data into a single csv file. \n",
    "\n",
    "Note the data scraping can be done from the website directly without downloading the HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "files = glob('web/*.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('web/page1.html', encoding='utf-8') as f:\n",
    "    result_soup = BeautifulSoup(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_data(result_soup):\n",
    "    ''' Take a beautifulsoup object, extract the table head, \n",
    "    extract air pollution data, and return a dataframe.\n",
    "    '''\n",
    "    table = result_soup.find_all(attrs = {'id':'table_mn_div'})[0]\n",
    "    table = table.table.tbody\n",
    "    print('obtain header text')\n",
    "    head = table.find_all('tr')[0]\n",
    "    head_text = [text for text in head.stripped_strings]\n",
    "    print('obtain body data')\n",
    "    body = table.find_all('tr')[1:]\n",
    "    \n",
    "    matrix = []\n",
    "    matrix = np.hstack(head_text)\n",
    "\n",
    "    for row in body:\n",
    "        data_s = row.find_all('input')\n",
    "        if len(data_s) != 0:\n",
    "            row_data = [data['value'] for data in data_s]\n",
    "            matrix = np.vstack((matrix, row_data))\n",
    "            \n",
    "    print('build a dataframe')\n",
    "    page_df = pd.DataFrame(matrix[1:,:], columns=matrix[0,:])\n",
    "    return page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n"
     ]
    }
   ],
   "source": [
    "# test the function on a single file\n",
    "with open('web/page1.html', encoding='utf-8') as f:\n",
    "    result_soup = BeautifulSoup(f.read())\n",
    "    \n",
    "page_df = page_data(result_soup)\n",
    "df = pd.DataFrame()\n",
    "df = pd.concat([page_df,page_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty data frame\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n",
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n",
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n",
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n",
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n",
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n",
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n",
      "obtain header text\n",
      "obtain body data\n",
      "build a dataframe\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        result_soup = BeautifulSoup(f.read())\n",
    "    \n",
    "    page_df = page_data(result_soup)\n",
    "    df = pd.concat([df,page_df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>2019,01,17,00,00,00</td>\n",
       "      <td>2019,01,17,01,00,00</td>\n",
       "      <td>2019,01,17,02,00,00</td>\n",
       "      <td>2019,01,17,03,00,00</td>\n",
       "      <td>2019,01,17,04,00,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_CO (ppm)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_NO (ppb)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_NOX (ppb)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_NO2 (ppb)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_SO2 (ppb)</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_THC (ppm)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_CH4 (ppm)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_THCNM (ppm)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_O3 (ppb)</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_PM10 (ug/m3)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_WS (m/s)</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_WD (Degree)</th>\n",
       "      <td>10.42</td>\n",
       "      <td>78.22</td>\n",
       "      <td>56.39</td>\n",
       "      <td>58.55</td>\n",
       "      <td>84.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_TEMP (Degree)</th>\n",
       "      <td>28.39</td>\n",
       "      <td>23.96</td>\n",
       "      <td>21.43</td>\n",
       "      <td>26.81</td>\n",
       "      <td>26.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_RH (%)</th>\n",
       "      <td>51.29</td>\n",
       "      <td>51.70</td>\n",
       "      <td>53.26</td>\n",
       "      <td>56.92</td>\n",
       "      <td>56.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_SRAD (w/m2)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_NRAD (w/m2)</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_BP (mmHG)</th>\n",
       "      <td>756.77</td>\n",
       "      <td>756.59</td>\n",
       "      <td>756.09</td>\n",
       "      <td>755.92</td>\n",
       "      <td>756.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_SD (Degree)</th>\n",
       "      <td>45.43</td>\n",
       "      <td>52.96</td>\n",
       "      <td>62.94</td>\n",
       "      <td>55.29</td>\n",
       "      <td>44.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_RAIN (m/s)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11t_PM2.5 (ug/m3)</th>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0                    1  \\\n",
       "Date               2019,01,17,00,00,00  2019,01,17,01,00,00   \n",
       "11t_CO (ppm)                         -                    -   \n",
       "11t_NO (ppb)                         -                    -   \n",
       "11t_NOX (ppb)                        -                    -   \n",
       "11t_NO2 (ppb)                        -                    -   \n",
       "11t_SO2 (ppb)                        3                    4   \n",
       "11t_THC (ppm)                        -                    -   \n",
       "11t_CH4 (ppm)                        -                    -   \n",
       "11t_THCNM (ppm)                      -                    -   \n",
       "11t_O3 (ppb)                         3                    6   \n",
       "11t_PM10 (ug/m3)                     -                    -   \n",
       "11t_WS (m/s)                      0.28                 0.20   \n",
       "11t_WD (Degree)                  10.42                78.22   \n",
       "11t_TEMP (Degree)                28.39                23.96   \n",
       "11t_RH (%)                       51.29                51.70   \n",
       "11t_SRAD (w/m2)                      -                    -   \n",
       "11t_NRAD (w/m2)                      -                    -   \n",
       "11t_BP (mmHG)                   756.77               756.59   \n",
       "11t_SD (Degree)                  45.43                52.96   \n",
       "11t_RAIN (m/s)                    0.00                 0.00   \n",
       "11t_PM2.5 (ug/m3)                   53                   48   \n",
       "\n",
       "                                     2                    3  \\\n",
       "Date               2019,01,17,02,00,00  2019,01,17,03,00,00   \n",
       "11t_CO (ppm)                         -                    -   \n",
       "11t_NO (ppb)                         -                    -   \n",
       "11t_NOX (ppb)                        -                    -   \n",
       "11t_NO2 (ppb)                        -                    -   \n",
       "11t_SO2 (ppb)                        3                    3   \n",
       "11t_THC (ppm)                        -                    -   \n",
       "11t_CH4 (ppm)                        -                    -   \n",
       "11t_THCNM (ppm)                      -                    -   \n",
       "11t_O3 (ppb)                        11                   18   \n",
       "11t_PM10 (ug/m3)                     -                    -   \n",
       "11t_WS (m/s)                      0.13                 0.18   \n",
       "11t_WD (Degree)                  56.39                58.55   \n",
       "11t_TEMP (Degree)                21.43                26.81   \n",
       "11t_RH (%)                       53.26                56.92   \n",
       "11t_SRAD (w/m2)                      -                    -   \n",
       "11t_NRAD (w/m2)                      -                    -   \n",
       "11t_BP (mmHG)                   756.09               755.92   \n",
       "11t_SD (Degree)                  62.94                55.29   \n",
       "11t_RAIN (m/s)                    0.00                 0.00   \n",
       "11t_PM2.5 (ug/m3)                   54                   59   \n",
       "\n",
       "                                     4  \n",
       "Date               2019,01,17,04,00,00  \n",
       "11t_CO (ppm)                         -  \n",
       "11t_NO (ppb)                         -  \n",
       "11t_NOX (ppb)                        -  \n",
       "11t_NO2 (ppb)                        -  \n",
       "11t_SO2 (ppb)                        3  \n",
       "11t_THC (ppm)                        -  \n",
       "11t_CH4 (ppm)                        -  \n",
       "11t_THCNM (ppm)                      -  \n",
       "11t_O3 (ppb)                        17  \n",
       "11t_PM10 (ug/m3)                     -  \n",
       "11t_WS (m/s)                      0.30  \n",
       "11t_WD (Degree)                  84.87  \n",
       "11t_TEMP (Degree)                26.89  \n",
       "11t_RH (%)                       56.35  \n",
       "11t_SRAD (w/m2)                      -  \n",
       "11t_NRAD (w/m2)                      -  \n",
       "11t_BP (mmHG)                   756.14  \n",
       "11t_SD (Degree)                  44.66  \n",
       "11t_RAIN (m/s)                    0.00  \n",
       "11t_PM2.5 (ug/m3)                   56  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as a csv file\n",
    "df.to_csv('data/aqmthai.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape many measurement stations\n",
    "\n",
    "One might be interested in the air pollution in your own province or would like to see variation among stations in the same province.  Bangkok itself has five stations. Some stations are on busy streets and some are in the outskirt. Perhaps, there is less air pollution in the outskirt. With a small adjustment to the above code, one can obtain the air pollution data from the stations that you are interested in. \n",
    "\n",
    "First, I start with opening the website using selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "url='http://www.aqmthai.com/public_report.php'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the code above into functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pages(sta_index):\n",
    "    # select station\n",
    "    station = Select(browser.find_element_by_css_selector('select[id=\"stationId\"]'))\n",
    "    station.select_by_index(sta_index)\n",
    "\n",
    "    \n",
    "    #select parameters to display\n",
    "    param = Select(browser.find_element_by_id('parameterSelected'))\n",
    "    #values = ['CO', 'O3', 'PM10', 'WS','WD', 'TEMP','SRAD','NRAD','RAIN', 'SD']\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # each staton has different parameter options \n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    select = soup.find_all(attrs={'id':'parameterSelected'})[0]\n",
    "    options = len(select.find_all('option'))\n",
    "    print(options)\n",
    "    \n",
    "    #select parameters\n",
    "    for i in range(options):\n",
    "        param.select_by_index(i)\n",
    "        \n",
    "    #select time\n",
    "    start_hr = Select(browser.find_element_by_id('startHour'))\n",
    "    start_hr.select_by_index(0)\n",
    "    start_min = Select(browser.find_element_by_id('startMin'))\n",
    "    start_min.select_by_index(0)\n",
    "    stop_hr = Select(browser.find_element_by_id('endHour'))\n",
    "    stop_hr.select_by_index(23)\n",
    "    stop_min = Select(browser.find_element_by_id('endMin'))\n",
    "    stop_min.select_by_index(59)\n",
    "    \n",
    "    #Retrive data \n",
    "    button = browser.find_element_by_name('bt_show_table')\n",
    "    button.click()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_param():\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    select = soup.find_all(attrs={'id':'parameterSelected'})[0]\n",
    "    return len(select.find_all('option'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_through_page(sta_index):\n",
    "    #download webpage as html file for scraping \n",
    "    page = browser.page_source\n",
    "    # include the file name in the station index\n",
    "    save_page(page, f'web2/{str(sta_index)}page1.html')\n",
    "        \n",
    "    nums =[str(i) for i in range(2,9)]\n",
    "    # click the next button to display the next page. There are 7 more pages \n",
    "    for num in nums:\n",
    "        next_button = browser.find_element_by_name('bt_next_page')\n",
    "        next_button.click()\n",
    "        time.sleep(5)\n",
    "        page = browser.page_source\n",
    "        save_page(page, f'web2/{str(sta_index)}page'+num+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_page(page, filename):\n",
    "    with open(filename,'w', encoding='utf-8') as f:\n",
    "        f.write(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the station number by index. Here, I select all stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "done with 1\n",
      "13\n",
      "done with 2\n",
      "13\n",
      "done with 3\n",
      "15\n",
      "done with 4\n",
      "20\n",
      "done with 5\n",
      "16\n",
      "done with 6\n",
      "17\n",
      "done with 7\n",
      "15\n",
      "done with 8\n",
      "14\n",
      "done with 9\n",
      "14\n",
      "done with 10\n",
      "19\n",
      "done with 11\n",
      "17\n",
      "done with 12\n",
      "16\n",
      "done with 13\n",
      "16\n",
      "done with 14\n",
      "10\n",
      "done with 15\n",
      "12\n",
      "done with 16\n",
      "13\n",
      "done with 17\n",
      "19\n",
      "done with 18\n",
      "26\n",
      "done with 19\n",
      "20\n",
      "done with 20\n",
      "21\n",
      "done with 21\n",
      "10\n",
      "done with 22\n",
      "15\n",
      "done with 23\n",
      "11\n",
      "done with 24\n",
      "17\n",
      "done with 25\n",
      "16\n",
      "done with 26\n",
      "17\n",
      "done with 27\n",
      "20\n",
      "done with 28\n",
      "12\n",
      "done with 29\n",
      "17\n",
      "done with 30\n",
      "17\n",
      "done with 31\n",
      "17\n",
      "done with 32\n",
      "16\n",
      "done with 33\n",
      "16\n",
      "done with 34\n",
      "14\n",
      "done with 35\n",
      "15\n",
      "done with 36\n",
      "10\n",
      "done with 37\n",
      "20\n",
      "done with 38\n",
      "12\n",
      "done with 39\n",
      "16\n",
      "done with 40\n",
      "13\n",
      "done with 41\n",
      "13\n",
      "done with 42\n",
      "12\n",
      "done with 43\n",
      "11\n",
      "done with 44\n",
      "10\n",
      "done with 45\n",
      "12\n",
      "done with 46\n",
      "13\n",
      "done with 47\n",
      "14\n",
      "done with 48\n",
      "14\n",
      "done with 49\n",
      "16\n",
      "done with 50\n",
      "16\n",
      "done with 51\n",
      "8\n",
      "done with 52\n",
      "8\n",
      "done with 53\n",
      "10\n",
      "done with 54\n",
      "34\n",
      "done with 55\n",
      "16\n",
      "done with 56\n",
      "12\n",
      "done with 57\n",
      "14\n",
      "done with 58\n",
      "14\n",
      "done with 59\n",
      "14\n",
      "done with 60\n"
     ]
    }
   ],
   "source": [
    "for sta_index in range(1,61):\n",
    "    browser.get(url)\n",
    "    display_pages(sta_index)\n",
    "    go_through_page(sta_index)\n",
    "    print('done with station', sta_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
